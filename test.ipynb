{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a6b926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba18ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathsManager:\n",
    "    def __init__(self, custom_root: Optional[Path] = None):\n",
    "        \"\"\"\n",
    "        Initialize paths manager with optional custom root directory.\n",
    "        \n",
    "        Args:\n",
    "            custom_root: Optional custom root directory path. If None, uses default \"data\" directory.\n",
    "        \"\"\"\n",
    "        self.root_data = custom_root if custom_root else Path(\"data\")\n",
    "        if isinstance(self.root_data, str):\n",
    "            self.root_data = Path(self.root_data)\n",
    "        self._validate_root_directory()\n",
    "        \n",
    "        # Main directories\n",
    "        self.root_spectrograms = self.root_data / \"spectrograms_dataset\"\n",
    "        self.root_voices = self.root_data / \"speech\"\n",
    "        \n",
    "        # # Reference files\n",
    "        # self.reference_files = {\n",
    "        #     'train': self.root_voices / \"references\" / \"train_index.csv\",\n",
    "        #     'test': self.root_voices / \"references\" / \"test_index.csv\",\n",
    "        #     'spectrograms': self.root_spectrograms / \"spectrograms_index.csv\",\n",
    "        #     'unique_speakers': self.root_spectrograms / \"unique_speakers.csv\"\n",
    "        # }\n",
    "\n",
    "    def _validate_root_directory(self) -> None:\n",
    "        \"\"\"Check if root directory exists or can be created.\"\"\"\n",
    "        try:\n",
    "            self.root_data.mkdir(parents=True, exist_ok=True)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to initialize root directory at {self.root_data}: {e}\")\n",
    "        \n",
    "    def _create_directories(self) -> None:\n",
    "        \"\"\"Create necessary directories if they don't exist.\"\"\"\n",
    "        for directory in [self.root_spectrograms, self.root_voices]:\n",
    "            directory.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e7dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchaudio\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "class SpectrogramDatasetGenerator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        paths_manager,\n",
    "        df,\n",
    "        sample_rate: int = 16000,\n",
    "        desired_duration_sec: int = 5,\n",
    "        n_mels: int = 80,\n",
    "        n_fft: int = 400,\n",
    "        hop_length: int = 160,\n",
    "        eps: float = 1e-9,\n",
    "        format: str = \"pt\"\n",
    "    ):\n",
    "        self.paths_manager = paths_manager\n",
    "        self.sample_rate = sample_rate\n",
    "        self.desired_duration_sec = 5\n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.eps = eps\n",
    "        self.format = format\n",
    "        self.df = df\n",
    "\n",
    "        self.mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=self.sample_rate,\n",
    "            n_mels=self.n_mels,\n",
    "            n_fft=self.n_fft,\n",
    "            win_length=self.n_fft,\n",
    "            hop_length=self.hop_length,\n",
    "            power=2.0\n",
    "        )\n",
    "\n",
    "        if self.format not in [\"pt\"]:\n",
    "            raise ValueError(f\"Unsupported format: {self.format}. Choose 'pt'.\")\n",
    "\n",
    "    def generate_spectrograms(self) -> None:\n",
    "        # all_files = self._get_audio_files()\n",
    "        all_files = [os.path.join(self.paths_manager.root_data.parent, file) for file in self.df['filename'].values if file.endswith('.wav')]\n",
    "\n",
    "        for file_path in tqdm(all_files, desc=\"Generating spectrograms\"):\n",
    "            try:\n",
    "                output_path = self._get_output_path(file_path)\n",
    "                # Sprawdzenie czy spektrogram już istnieje\n",
    "                if output_path.exists():\n",
    "                    continue  # Pomija tworzenie, jeśli już istnieje\n",
    "\n",
    "                waveform, sample_rate = self._load_audio(file_path)\n",
    "                if waveform is not None:\n",
    "                    spectrogram = self._create_spectrogram(waveform)\n",
    "                    \n",
    "                    self._save_spectrogram(spectrogram, output_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    def _get_audio_files(self) -> List[str]:\n",
    "        audio_files = []\n",
    "        for root, _, files in os.walk(self.paths_manager.root_voices):\n",
    "            for file in files:\n",
    "                if file.endswith('.wav'):\n",
    "                    audio_files.append(os.path.join(root, file))\n",
    "        return audio_files\n",
    "\n",
    "    def _load_audio(self, filepath: str) -> Tuple[Optional[torch.Tensor], Optional[int]]:\n",
    "        try:\n",
    "            waveform, sample_rate = torchaudio.load(filepath)\n",
    "\n",
    "            # 1. Mono\n",
    "            if waveform.shape[0] > 1:\n",
    "                waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "            # 2. Normalizacja RMS\n",
    "            waveform = self._normalize_rms(waveform)\n",
    "\n",
    "            # 3. Przycinanie ciszy (VAD)\n",
    "            waveform = self._trim_silence(waveform, sample_rate)\n",
    "\n",
    "            # 4. Resampling\n",
    "            if sample_rate != self.sample_rate:\n",
    "                resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=self.sample_rate)\n",
    "                waveform = resampler(waveform)\n",
    "\n",
    "            # num_samples = self.desired_duration_sec * self.sample_rate\n",
    "            # current_len = waveform.shape[1]\n",
    "            # if current_len >= num_samples:\n",
    "            #     max_start = current_len - num_samples\n",
    "            #     start = random.randint(0, max_start) if max_start > 0 else 0\n",
    "            #     end   = start + num_samples\n",
    "            #     waveform = waveform[:, start:end]       # <<-- random 5s from the audio\n",
    "            # else:\n",
    "            #     # Opcjonalnie: Padding, jeśli dźwięk krótszy niż 5 sek.\n",
    "            #     repeats = num_samples // current_len + 1  # liczba powtórzeń potrzebna do osiągnięcia długości\n",
    "            #     waveform = waveform.repeat(1, repeats)[:, :num_samples]\n",
    "\n",
    "            return waveform, self.sample_rate\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filepath}: {str(e)}\")\n",
    "            return None, None\n",
    "\n",
    "    def _create_spectrogram(self, waveform: torch.Tensor) -> torch.Tensor:\n",
    "        # # 5. Pre-emphasis\n",
    "        waveform = torchaudio.functional.preemphasis(waveform, coeff=0.97)\n",
    "\n",
    "        # 6. Mel-spektrogram i log\n",
    "        mel_spec = self.mel_spectrogram(waveform)\n",
    "        return torch.log(mel_spec + self.eps)\n",
    "\n",
    "    def _normalize_rms(self, waveform: torch.Tensor, target_dbfs: float = -20.0) -> torch.Tensor:\n",
    "        rms = waveform.pow(2).mean().sqrt()\n",
    "        target_rms = 10 ** (target_dbfs / 20)\n",
    "        gain = target_rms / (rms + self.eps)\n",
    "        return waveform * gain\n",
    "\n",
    "    def _trim_silence(self, waveform: torch.Tensor, sample_rate: int) -> torch.Tensor:\n",
    "        vad = torchaudio.transforms.Vad(sample_rate=sample_rate)\n",
    "        return vad(waveform)\n",
    "    \n",
    "    def _get_output_path(self, input_path: str) -> Path:\n",
    "        relative_path = Path(input_path).relative_to(self.paths_manager.root_voices)\n",
    "        stem = relative_path.stem\n",
    "        output_dir = self.paths_manager.root_spectrograms / relative_path.parent\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        return output_dir / f\"{stem}.pt\"\n",
    "\n",
    "    def _save_spectrogram(self, spectrogram: torch.Tensor, output_path: Path) -> None:\n",
    "\n",
    "        torch.save(spectrogram, output_path)\n",
    "    \n",
    "\n",
    "    def display_spectrograms(\n",
    "        self,\n",
    "        pt_paths: List[Union[str, Path]],\n",
    "        cols: int = 3,\n",
    "        figsize: tuple = (14, 4),\n",
    "        show_freq_axis: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Wyświetl siatkę spektrogramów z osiami czasu, częstotliwości i legendą dB.\n",
    "\n",
    "        Args:\n",
    "            pt_paths: lista ścieżek do plików .pt\n",
    "            cols:     liczba kolumn w siatce\n",
    "            figsize:  rozmiar całej figury (szer., wys.) w calach\n",
    "            show_freq_axis: jeśli False -> ukrywa oś Y dla oszczędności miejsca\n",
    "        \"\"\"\n",
    "        if len(pt_paths) == 0:\n",
    "            print(\"Brak plików do wyświetlenia.\")\n",
    "            return\n",
    "\n",
    "        # ── parametry konwersji ramek -> sekundy ────────────────────\n",
    "        seconds_per_frame = self.hop_length / self.sample_rate\n",
    "\n",
    "        rows = math.ceil(len(pt_paths) / cols)\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=figsize, squeeze=False)\n",
    "\n",
    "        for ax, pt_path in zip(axes.flatten(), pt_paths):\n",
    "            spec = torch.load(pt_path).squeeze(0).cpu().numpy()   # [mels, frames]\n",
    "\n",
    "            # extent = [xmin, xmax, ymin, ymax] → tu: czas [s], mel-bin\n",
    "            xmax = spec.shape[1] * seconds_per_frame\n",
    "            extent = [0, xmax, 0, self.n_mels]\n",
    "\n",
    "            im = ax.imshow(\n",
    "                spec,\n",
    "                origin=\"lower\",\n",
    "                aspect=\"auto\",\n",
    "                extent=extent\n",
    "            )\n",
    "            ax.set_title(Path(pt_path).stem, fontsize=9)\n",
    "\n",
    "            # Osie\n",
    "            ax.set_xlabel(\"Czas [s]\")\n",
    "            if show_freq_axis:\n",
    "                ax.set_ylabel(\"Mel-pasm\")\n",
    "            else:\n",
    "                ax.set_yticks([])\n",
    "\n",
    "            # Colorbar (dB)\n",
    "            cb = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "            cb.set_label(\"Moc [dB]\")\n",
    "\n",
    "        # Ukryj puste osie\n",
    "        for ax in axes.flatten()[len(pt_paths):]:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d318463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"data/train_df.csv\")\n",
    "df_val = pd.read_csv(\"data/val_df.csv\")\n",
    "df_test = pd.read_csv(\"data/test_df.csv\")\n",
    "# df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "df = pd.concat([df_train, df_val, df_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b443930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating spectrograms: 100%|██████████| 4224/4224 [00:00<00:00, 10620.20it/s]\n"
     ]
    }
   ],
   "source": [
    "custom_root = '/net/pr2/projects/plgrid/plggdnnp/datasets/VOiCES_devkit/distant-16k'\n",
    "paths_manager = PathsManager(custom_root=custom_root)\n",
    "generator = SpectrogramDatasetGenerator(paths_manager, df=df)\n",
    "generator.generate_spectrograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76aabde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdz czy folder istnieje:\n",
    "if paths_manager.root_voices.exists():\n",
    "    print(f\"Folder {paths_manager.root_voices} istnieje.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ef0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
